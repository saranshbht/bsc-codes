{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import cluster, metrics, datasets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application of k-means clustering algorithm on HRTU2 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin score for k = 2 : 0.6793486550368992\n",
      "Davies-Bouldin score for k = 3 : 0.7481502337059877\n",
      "Davies-Bouldin score for k = 4 : 0.7837697587959213\n",
      "Davies-Bouldin score for k = 5 : 0.7399607288949918\n",
      "Davies-Bouldin score for k = 6 : 0.7303417368032523\n",
      "Davies-Bouldin score for k = 7 : 0.7391748881771709\n",
      "Davies-Bouldin score for k = 8 : 0.7443313258605988\n",
      "Davies-Bouldin score for k = 9 : 0.7571938542886659\n",
      "Davies-Bouldin score for k = 10 : 0.7834505333834458\n",
      "k = 2 gives best Davies-Bouldin score( 0.6793486550368992 )\n"
     ]
    }
   ],
   "source": [
    "hrtu = pd.read_csv('Datasets/HTRU2/HTRU_2.csv', header=None)\n",
    "x = hrtu.iloc[:, :-1].to_numpy()\n",
    "\n",
    "k = range(1, 10)\n",
    "min_dbscore = 10**10\n",
    "kmin = 1\n",
    "for k in range(2, 11):\n",
    "    kmeans = cluster.KMeans(n_clusters=k)\n",
    "    kmeans.fit(x)\n",
    "    # # print(y)\n",
    "    labels = kmeans.labels_\n",
    "    dbscore = metrics.davies_bouldin_score(x, labels)\n",
    "    if dbscore < min_dbscore:\n",
    "        min_dbscore = dbscore\n",
    "        kmin = k\n",
    "    print(\"Davies-Bouldin score for k =\", k, \":\", dbscore)\n",
    "    \n",
    "print(\"k =\", kmin, \"gives best Davies-Bouldin score(\", min_dbscore, \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application of DBSCAN clustering algorithm on Perfume dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin score for eps = 10.0 and min_samples = 5.0 : 2.3247293875323876\n",
      "Davies-Bouldin score for eps = 10.0 and min_samples = 6.0 : 2.6463062784868887\n",
      "Davies-Bouldin score for eps = 10.0 and min_samples = 7.0 : 3.0149416667256794\n",
      "Davies-Bouldin score for eps = 10.0 and min_samples = 8.0 : 5.158858411472511\n",
      "Davies-Bouldin score for eps = 10.0 and min_samples = 9.0 : 5.158858411472511\n",
      "Davies-Bouldin score for eps = 10.0 and min_samples = 10.0 : 8.449327546675814\n",
      "Davies-Bouldin score for eps = 46.41588833612777 and min_samples = 5.0 : 2.3404706698645232\n",
      "Davies-Bouldin score for eps = 46.41588833612777 and min_samples = 6.0 : 2.3404706698645232\n",
      "Davies-Bouldin score for eps = 46.41588833612777 and min_samples = 7.0 : 6.15642532769999\n",
      "Davies-Bouldin score for eps = 46.41588833612777 and min_samples = 8.0 : 2.536371890319451\n",
      "Davies-Bouldin score for eps = 46.41588833612777 and min_samples = 9.0 : 1.5106699602677343\n",
      "Davies-Bouldin score for eps = 46.41588833612777 and min_samples = 10.0 : 1.7313378492867784\n",
      "Davies-Bouldin score for eps = 215.44346900318823 and min_samples = 5.0 : 6.618553348287052\n",
      "Davies-Bouldin score for eps = 215.44346900318823 and min_samples = 6.0 : 6.618553348287052\n",
      "Davies-Bouldin score for eps = 215.44346900318823 and min_samples = 7.0 : 2.5675311141283403\n",
      "Davies-Bouldin score for eps = 215.44346900318823 and min_samples = 8.0 : 1.7435243147882902\n",
      "Davies-Bouldin score for eps = 215.44346900318823 and min_samples = 9.0 : 1.1399204246928243\n",
      "Davies-Bouldin score for eps = 215.44346900318823 and min_samples = 10.0 : 1.1399204246928243\n",
      "Davies-Bouldin score for eps = 1000.0 and min_samples = 5.0 : 0.28930752617841343\n",
      "Davies-Bouldin score for eps = 1000.0 and min_samples = 6.0 : 0.28930752617841343\n",
      "Davies-Bouldin score for eps = 1000.0 and min_samples = 7.0 : 0.28930752617841343\n",
      "Davies-Bouldin score for eps = 1000.0 and min_samples = 8.0 : 0.28930752617841343\n",
      "Davies-Bouldin score for eps = 1000.0 and min_samples = 9.0 : 0.28930752617841343\n",
      "Davies-Bouldin score for eps = 1000.0 and min_samples = 10.0 : 0.28930752617841343\n",
      "eps = 1000.0 and min_samples = 5.0 gives best Davies-Bouldin score( 0.28930752617841343 )\n"
     ]
    }
   ],
   "source": [
    "perfume = pd.read_excel('Datasets/Perfume_Data/perfume_data.xlsx', header=None)\n",
    "x = perfume.iloc[:, 1:].to_numpy().flatten()\n",
    "np.random.shuffle(x)\n",
    "x.shape = (-1, 1)\n",
    "\n",
    "min_dbscore = 10**10\n",
    "eps_min, samples_min = -1, -1\n",
    "epsilon = np.logspace(1, 3, 4)\n",
    "samples = np.linspace(5, 10, 6)\n",
    "for eps in epsilon:\n",
    "    for min_samples in samples:\n",
    "        db = cluster.DBSCAN(eps=eps, min_samples=min_samples).fit(x)\n",
    "        labels = db.labels_\n",
    "#         print(labels)\n",
    "#         print(len(set(labels)))\n",
    "        dbscore = metrics.davies_bouldin_score(x, labels)\n",
    "        if dbscore < min_dbscore:\n",
    "            min_dbscore = dbscore\n",
    "            eps_min = eps\n",
    "            samples_min = min_samples\n",
    "        print(\"Davies-Bouldin score for eps =\", eps, \"and min_samples =\", min_samples, \":\", dbscore)\n",
    "    \n",
    "print(\"eps =\", eps_min, \"and min_samples =\", samples_min, \"gives best Davies-Bouldin score(\", min_dbscore, \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application of Agglomerative clustering algorithm on sklearn's toy dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Davies-Bouldin score for average linkage: 0.7874623048058049\n",
      "Davies-Bouldin score for complete linkage: 0.8074533760682475\n",
      "Davies-Bouldin score for single linkage: 1.1814187686460293\n",
      "Average linkage gives best Davies-Bouldin score( 0.7874623048058049 )\n"
     ]
    }
   ],
   "source": [
    "moons = datasets.make_moons()\n",
    "x = moons[0]\n",
    "\n",
    "min_dbscore = 10**10\n",
    "min_linkage = ''\n",
    "for linkage in ['average', 'complete', 'single']:\n",
    "    hierarchical = cluster.AgglomerativeClustering(linkage=linkage)\n",
    "    hierarchical.fit(x)\n",
    "    labels = hierarchical.labels_\n",
    "    dbscore = metrics.davies_bouldin_score(x, labels)\n",
    "    if dbscore < min_dbscore:\n",
    "        min_dbscore = dbscore\n",
    "        min_linkage = linkage\n",
    "    print(\"Davies-Bouldin score for\", linkage, \"linkage:\", dbscore)\n",
    "print(min_linkage.capitalize(), \"linkage gives best Davies-Bouldin score(\", min_dbscore, \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
